# 🚀 Multimodal Learning Projects by Mustafa Shoukat

## 📚 Projects Overview

### 1. **🔍 Multimodal_RAG (Text, Image, Video).ipynb**
   - **📝 Description**: This project focuses on implementing an end-to-end Multimodal Retrieval-Augmented Generation (RAG) system. The model analyzes retrieved multimodal context (text, images, and videos) to generate insightful and coherent answers.
   - **🔧 Key Techniques**: 
     - 🎯 Contrastive learning for multimodal model training.
     - 🖼️ Visual instruction tuning to enhance LLMs' understanding of multimodal data.
     - 🌐 Real-world applications like cross-modal retrieval and reasoning.

### 2. **🎥 Multimodal_Move_With_Open_AI_Recommender.ipynb**
   - **📝 Description**: A project that builds an any-to-any multimodal search and recommender system. This system compares similarities across multiple modalities (text, image, video) to suggest relevant items.
   - **🔧 Key Techniques**:
     - 💡 Multi-vector recommender system.
     - 🔄 Cross-modality context retrieval.
     - 📊 Integration of various data types to enhance recommendation accuracy.

### 3. **📄 Invoice Extractor System.ipynb**
   - **📝 Description**: This notebook explores industry applications of multimodal learning by visually analyzing invoices and flowcharts. The system extracts and structures data from these documents, demonstrating practical use cases for multimodal AI in business settings.
   - **🔧 Key Techniques**:
     - 🖼️ Document image processing.
     - 🧾 Structured data extraction from visual inputs.
     - 💼 Application of multimodal AI to automate business processes.

## 🧑‍💻 Author

**Mustafa Shoukat**  
- [LinkedIn](https://www.linkedin.com/in/mustafashoukat/)  
- [GitHub](https://github.com/Mustafa-Shoukat1)  
- [Kaggle](https://www.kaggle.com/mustafashoukat)
